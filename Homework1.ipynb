{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks — Regression (week 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield eval(l)       \n",
    "print \"Reading data...\"\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print \"done\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. What is the distribution of ratings in the dataset (for ‘review/taste’)? That is, how many 1-star, 2-star, 3-star (etc.) reviews are there? You may write out the values or include a simple plot (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [d for d in data if 'review/taste' in d]\n",
    "\n",
    "def feature(datum):\n",
    "    feat = datum['review/taste']\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data1]\n",
    "\n",
    "a = np.arange(0.5,5.5,0.5)\n",
    "f = []\n",
    "for x in a:\n",
    "    f.append(X.count(x))\n",
    "    \n",
    "df = pd.DataFrame(f,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beer/ABV': 3.5,\n",
       " 'beer/beerId': '436',\n",
       " 'beer/brewerId': '163',\n",
       " 'beer/name': 'Amstel Light',\n",
       " 'beer/style': 'Light Lager',\n",
       " 'review/appearance': 2.0,\n",
       " 'review/aroma': 2.0,\n",
       " 'review/overall': 1.5,\n",
       " 'review/palate': 2.0,\n",
       " 'review/taste': 2.0,\n",
       " 'review/text': 'The color of chardonnay with about as much head as a glass of wine.\\t\\tAroma is initially a bitter skunky funk, some grassy straw notes, but if you concentrate you can pick out some bready honey malt lying way beneath.\\t\\tFlavor is similar to the nose, initially skunky, but some notes of corn and honey malt emerge as it rolls through the mouth.\\t\\tMouthfeel is slick and watery, but finishes tingly, very crisp. Very low drinkability. I know a lot of people like this as a low calorie lighter import, but there really is not much flavor, and what flavor is there is funky and skunky.',\n",
       " 'review/timeStruct': {'hour': 23,\n",
       "  'isdst': 0,\n",
       "  'mday': 8,\n",
       "  'min': 17,\n",
       "  'mon': 3,\n",
       "  'sec': 29,\n",
       "  'wday': 6,\n",
       "  'yday': 67,\n",
       "  'year': 2009},\n",
       " 'review/timeUnix': 1236554249,\n",
       " 'user/gender': 'Male',\n",
       " 'user/profileName': 'far333'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11319c6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind='bar',color='b',alpha = 0.7)\n",
    "plt.xlabel('Ratings') # Label X axis\n",
    "plt.ylabel('Count') #  Label Y axis\n",
    "plt.title('Beer') # titles\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Train a simple predictor to predict a beer’s ‘taste’ score using two features: 1)beer is a Hefeweizen 2) beer/ABV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "data2 = [d for d in data if d.has_key('beer/style')]\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1,datum['beer/ABV']]\n",
    "  if datum['beer/style'] == 'Hefeweizen':\n",
    "    feat.append(1)\n",
    "  else:\n",
    "    feat.append(0)\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data2]\n",
    "y = [d['review/taste'] for d in data2]\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.11795084,  0.10877902, -0.05637406])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theta0 = 3.11795084  \n",
    "the constant attributer\n",
    "\n",
    "theta1 = 0.10877902\n",
    "the influence of \"ABV\" attributer\n",
    "\n",
    "theta2 = -0.05637406\n",
    "the influence of attributer that if beer is a Hefeweizen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Split the data into two equal fractions – the first half for training, the second half for testing (based on the order they appear in the file). Train the same model as above on the training set only. What is the model’s MSE on the training and on the test set (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "data3 = data[:25000]\n",
    "data4 = data[25000:]\n",
    "\n",
    "#data3 = [d for d in data3 if d.has_key('beer/style')]\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1,(1 if datum['beer/style'] == 'Hefeweizen' else 0) ,  datum['beer/ABV']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data3]\n",
    "y = [d['review/taste'] for d in data3]\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "mse1 = residuals/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.matrix(theta).T\n",
    "\n",
    "data4 = [d for d in data4 if d.has_key('beer/style')]\n",
    "X = [feature(d) for d in data4]\n",
    "y = [d['review/taste'] for d in data4]\n",
    "X = np.matrix(X)\n",
    "y = np.matrix(y).T\n",
    "\n",
    "diff = X*theta - y\n",
    "diffSq = diff.T*diff\n",
    "mse2 = diffSq / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.42370652]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TEST MSE\n",
    "mse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48396806])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TRAINING MSE\n",
    "mse1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Repeat the above experiment by using a random 50% split of the data (i.e., half for training, half for testing, after first shuffling the data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data\n",
    "random.shuffle(data5)\n",
    "data6 = data5[:25000]\n",
    "data7 = data5[25000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#data6 = [d for d in data6 if d.has_key('beer/style')]\n",
    "#data7 = [d for d in data7 if d.has_key('beer/style')]\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1,(1 if datum['beer/style'] == 'Hefeweizen' else 0) ,  datum['beer/ABV']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data6]\n",
    "y = [d['review/taste'] for d in data6]\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "mse3 = residuals/len(y)\n",
    "\n",
    "theta = np.matrix(theta).T\n",
    "\n",
    "X = [feature(d) for d in data7]\n",
    "y = [d['review/taste'] for d in data7]\n",
    "X = np.matrix(X)\n",
    "y = np.matrix(y).T\n",
    "diff = X*theta - y\n",
    "diffSq = diff.T*diff\n",
    "mse4 = diffSq / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44789317])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.45147536]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After shuffling the data sequence, mse of training data and testing data are smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Modify your experiment from Question 4 to use the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def feature(datum):\n",
    "  feat1 = datum['beer/ABV'] if datum['beer/style'] == 'Hefeweizen' else 0\n",
    "  feat2 = datum['beer/ABV'] if datum['beer/style'] != 'Hefeweizen' else 0\n",
    "  feat = [1,feat1, feat2]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data6]\n",
    "y = [d['review/taste'] for d in data6]\n",
    "theta,residuals,rank,s = np.linalg.lstsq(X, y)\n",
    "mse3 = residuals/len(y)\n",
    "\n",
    "theta = np.matrix(theta).T\n",
    "\n",
    "X = [feature(d) for d in data7]\n",
    "y = [d['review/taste'] for d in data7]\n",
    "X = np.matrix(X)\n",
    "y = np.matrix(y).T\n",
    "diff = X*theta - y\n",
    "diffSq = diff.T*diff\n",
    "mse4 = diffSq / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44788606])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.45147021]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.The model from Question 5 uses the same two features as the model from Question 4 and has the same dimensionality. Comment on why the two models might perform differently (1 mark).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the dimensionality for two models are same, but the input value are different. For the model of question 2-4, the feature looks like [1,ABV,1/0]. But for the model of question 5, the feature looks like [1,5.0,1] for the beer is Hefeweizen, and [1,0,5.0] for the beer is not the Hefeweizen for example. Plus, those two are all random shuffle dataset, as the result, the two models would perform differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks — Classification (week 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.First, let’s train a predictor that estimates whether a beer is a ‘Hefeweizen’ using five features describing its rating:\n",
    "[‘review/taste’, ‘review/appearance’, ‘review/aroma’, ‘review/palate’, ‘review/overall’]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [datum['review/taste'],datum['review/appearance'],datum['review/aroma'],datum['review/palate'],datum['review/overall']]\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data5]\n",
    "y = [\"Hefeweizen\" in b['beer/style'] for b in data5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:25000]\n",
    "y_train = y[:25000]\n",
    "\n",
    "X_test = X[25000:]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "train_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correct = train_predictions == y_train\n",
    "test_correct = test_predictions == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = float(sum(train_correct))/float(len(train_correct))\n",
    "test_acc = float(sum(test_correct))/float(len(test_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98824"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98704"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Considering same prediction problem as above, can you come up with a more accurate predictor (e.g. using features from the text, or otherwise)? Write down the feature vector you design, and report its train/test accuracy (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data8 = [d for d in data6 if \"Hefeweizen\" in d['beer/style']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beer/ABV': 4.9,\n",
       " 'beer/beerId': '1621',\n",
       " 'beer/brewerId': '394',\n",
       " 'beer/name': \"Stoudt's Weizen\",\n",
       " 'beer/style': 'Hefeweizen',\n",
       " 'review/appearance': 4.0,\n",
       " 'review/aroma': 3.5,\n",
       " 'review/overall': 4.0,\n",
       " 'review/palate': 3.5,\n",
       " 'review/taste': 4.0,\n",
       " 'review/text': 'Sweet wheat smell.  Cloudy white/yellow look with a creamy white head.  It lasts (the retention) for a while but not forever.  The taste is of yeast and clove.  Clean fresh finish.. not as mouth as I anticipated by its appearence.  The brew is a solid wheat selection for summer drinking.  You are also left with a thick malt coating of the tongue and throat which also has a banana clove as well.  Worth a try if you are a \"wheat head\" if not get the tripel instead.. trust me...',\n",
       " 'review/timeStruct': {'hour': 19,\n",
       "  'isdst': 0,\n",
       "  'mday': 16,\n",
       "  'min': 24,\n",
       "  'mon': 7,\n",
       "  'sec': 30,\n",
       "  'wday': 1,\n",
       "  'yday': 197,\n",
       "  'year': 2002},\n",
       " 'review/timeUnix': 1026847470,\n",
       " 'user/profileName': 'frank4sail'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data8[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [datum['review/taste'],datum['review/appearance'],datum['review/aroma'],datum['review/palate'],datum['review/overall']]\n",
    "    if \"Hefeweizen\" in d['beer/name']:\n",
    "        feat.append(1)\n",
    "    else:\n",
    "        feat.append(0)\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data5]\n",
    "y = [\"Hefeweizen\" in b['beer/style'] for b in data5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:25000]\n",
    "y_train = y[:25000]\n",
    "\n",
    "X_test = X[25000:]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "train_predictions[:10]\n",
    "\n",
    "train_correct = train_predictions == y_train\n",
    "test_correct = test_predictions == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = float(sum(train_correct))/float(len(train_correct))\n",
    "test_acc = float(sum(test_correct))/float(len(test_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99224"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99144"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
